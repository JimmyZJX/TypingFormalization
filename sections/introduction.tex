\section{Introduction}

Modern functional programming languages, such as Haskell or OCaml,
use sophisticated forms of type inference. The type systems of these languages are
descendents of Hindley-Milner~\cite{}, which was revolutionary at the
time in allowing type-inference to proceed without any type
annotation. The traditional Hindley-Milner type system supports
top-level \emph{implicit (parametric) polymorphism}. With implicit
polymorphism, type arguments of polymorphic functions are
automatically instantiated. Thus implicit polymorphism and the absense of
type annotations mean that the Hindley-Milner type system 
strikes a great balance between expressive power and usability. 

As functional languages evolved the need for more expressive
power has motivated language designers to look beyond Hindley-Milner.
In particular one popular direction has been to allow 
\emph{higher-ranked polymorphism} where polymorphic types can
occur anywhere in a type signature.  
An important challenge is that full type inference for higher-ranked
polymorphism is know to be undecidable~\cite{}. Therefore some type
annotations are necessary to guide type inference. In response to this 
challenge several decidable type systems requiring some annotations 
have been proposed~\cite{}. Two closely related type systems that 
support \emph{predicative} higher-ranked type inference were proposed 
by Peyton Jones et al.~\cite{} and Dunfield and
Krishnaswami (henceforth denoted as DK). 
These type systems are
popular among language designers and their ideas have been adopted by
several modern functional languages, including Haskell and PureScript.
In those type systems
type annotations are required for polymorphic arguments of functions,
but other type annotations can be omitted. A canonical example (here written in Haskell) is:
\begin{verbatim}
hpoly = (\f :: forall a. a -> a) -> (f 1, f 'c')
\end{verbatim}
The function \verb|hpoly| cannot be
type-checked in Hindley-Milner.  The type of \verb|hpoly| is the rank-2 type:
\verb|(forall a. a -> a) -> (Int, Char)|. Notably (and unlike
Hindley-Milner) the lambda argument \verb|f| requires a
\emph{polymorphic} type annotation.
This annotation is needed because the single universal quantifier
does not appear at the top-level. Instead it is used to quantify a
type variable \verb|a| used in the first argument of the
function. 
Despite these additional annotations, Peyton Jones et al. and DK's
type inference algorithms preserve many of the desirable properties 
of Hindley-Milner. For example the applications of \verb|f| implicitly 
instantiate the polymorphic type arguments of \verb|f|.

Despite the importance of type inference in practice and also in
academic research, there is little work in mechanically formalizing
such advanced forms of type inference in theorem provers. This is at
odds with the current trend of mechanical formalizations in
programming language research. In particular both the POPLMark
challenge~\cite{} and CompCert ~\cite{} have significantly promoted
the use of theorem provers to model various aspects of programming
languages. Indeed today there are routinely papers in top conferences
that use theorem provers to mechanically formalize: \emph{dynamic and
  static semantics} and their correctness properties~\cite{},
\emph{compiler correctness}~\cite{}, \emph{correctness of
  optimizations}~\cite{}, certain forms of \emph{abstract
  interpretation} or proofs involving \emph{logical relations}. The
main argument for mechanical formalizations is a simple one. Proofs
for programming languages tend to be \emph{long}, \emph{tedious} and
\emph{error-prone}. In such proofs it is very easy to make mistakes
that invalidate the whole development. Furthermore, readers and
reviewers often do not have time to look at the proofs carefuly to
check their correctnessness. Therefore errors can go unnoticed for a
long time.  Mechanical formalizations provide, in principle, a natural
solution for such problems. Theorem provers can automaticaly check and
validate the proofs, which removes the burden from checking from both
the person doing the proofs as well as readers or reviewers.

DK problem in lemma ??. Castagna problem in a recent type inference paper.

with the exception of some work
done on the formalization of 
certain aspects of Hindley-Milner type inference, we do not know 

This paper presents the first full mechanical formalization of the
metatheory for higher-ranked polymorphic type inference.
The system
that we formalize is the bidirectional type system by Dunfield and
Krishnaswami (DK)~\cite{}. We chose DK's type system because it is
quite elegant, well-documented and it comes with detailed manually
written proofs. Furthermore the system is adopted in practice by a few
real implementations of functional languages, including PureScript and
\bruno{others}.  The DK type system has two variants: a declarative
and an algorithmic one. The two variants have been been
\emph{manually} proved to be \emph{sound}, \emph{complete} and
\emph{decidable}.
We present a mechanical formalization in the Abella theorem prover for
DK's declarative type system using a different algorithm. While our
initial goal was to formalize both DK's declarative and algorithmic
versions, we faced technical challenges with the later, prompting us to find
an alternative.

One key challenge in type inference is variable binding,
because the algorithms typically do not rely simply on local
environments, but instead propagate information across judgements.
Yet, there is little work on how to deal with these complex forms of
binding in theorem provers. To keep track of variable scoping, DK's
algorithmic version employs input and output contexts to track
information that is discovered throught type inference. However
modelling output contexts in a theorem prover is non-trivial. Our
work takes a different approach by refining the idea of
\emph{worklists judgments}~\cite{}, proposed recently to mechanically
formalize an algorithm for \emph{polymorphic subtyping}.
However, a key challenge not addressed previously with
worklist judgements was how to deal with inference judgements.
In our work we show how worklist judgements can be extended to
deal with the inference judgements that are necessary for type-inference.
Furthermore we also present new techniques that enable precise tracking
of the scope of variables.

%% Polymorphic subtyping is one component of higher-ranked type inference, and
%% it is also a key part of DK's system.

Another challenge that we faced were missing details and sometimes
incorrect proofs/lemmas in DK's formalization. While DK's original
formalization comes with very well-written manual proofs, there are
several details missing, which complicate the task of writing a
mechanically verified proof. Perhaps more importantly, some
proofs/lemmas are wrong and it is not clear how to replace these by
other valid proofs/lemmas.


Despite the use of a different algorithm we prove the
same results by DK, although with significantly different proofs and
proof techniques. The calculus and its metatheory
have been fully formalized in the Abella theorem prover~\cite{AbellaDesc}. % Add at least one ref to make compile work normally

In summary, the contributions of this paper are:

\begin{itemize}

\item {\bf A full mechanical formalization of type inference with
  higher-ranked types:} Our work presents the first full mechanical formalization
  for type inference of higher ranked types. The formalization is done in the
  Abella theorem prover\cite{AbellaDesc} and it is available
  online\footnote{{\{bf Note to reviewers:} Due to the anonymous submission process
  the url is sent as part of the supplementary materials.}

\item {\bf A new algorithm for DK:} Our work proposes a novel algorithm that implements
  DK's declaratiuve bidirectional type systems. We prove the soundness ...

\item {\bf Worlists with inference judgments:}

\item {\bf Abella formalization:} The calculus and its metatheory
have been fully formalized in the .

\end{itemize}
