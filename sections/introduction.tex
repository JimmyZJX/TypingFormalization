\section{Introduction}
\bruno{Jimmy can you please add the references? Let me know if you have questions.}

Modern functional programming languages, such as Haskell or OCaml,
use sophisticated forms of type inference. The type systems of these languages are
descendents of Hindley-Milner~\cite{}, which was revolutionary at the
time in allowing type-inference to proceed without any type
annotation. The traditional Hindley-Milner type system supports
top-level \emph{implicit (parametric) polymorphism}. With implicit
polymorphism, type arguments of polymorphic functions are
automatically instantiated. Thus implicit polymorphism and the absense of
type annotations mean that the Hindley-Milner type system 
strikes a great balance between expressive power and usability. 

As functional languages evolved the need for more expressive
power has motivated language designers to look beyond Hindley-Milner.
In particular one popular direction is to allow 
\emph{higher-ranked polymorphism} where polymorphic types can
occur anywhere in a type signature.  
An important challenge is that full type inference for higher-ranked
polymorphism is know to be undecidable~\cite{}. Therefore some type
annotations are necessary to guide type inference. In response to this 
challenge several decidable type systems requiring some annotations 
have been proposed~\cite{}\bruno{works on impredicative type inference + DK and Peyton Jones}.
Two closely related type systems that 
support \emph{predicative} higher-ranked type inference were proposed 
by Peyton Jones et al.~\cite{} and Dunfield and
Krishnaswami~\cite{} (henceforth denoted as DK). 
These type systems are
popular among language designers and their ideas have been adopted by
several modern functional languages, including Haskell and PureScript.
In those type systems
type annotations are required for polymorphic arguments of functions,
but other type annotations can be omitted. A canonical example (here written in Haskell) is:
\begin{verbatim}
hpoly = (\f :: forall a. a -> a) -> (f 1, f 'c')
\end{verbatim}
The function \verb|hpoly| cannot be
type-checked in Hindley-Milner.  The type of \verb|hpoly| is the rank-2 type:
\verb|(forall a. a -> a) -> (Int, Char)|. Notably (and unlike
Hindley-Milner) the lambda argument \verb|f| requires a
\emph{polymorphic} type annotation.
This annotation is needed because the single universal quantifier
does not appear at the top-level. Instead it is used to quantify a
type variable \verb|a| used in the first argument of the
function. 
Despite these additional annotations, Peyton Jones et al. and DK's
type inference algorithms preserve many of the desirable properties 
of Hindley-Milner. For example the applications of \verb|f| implicitly 
instantiate the polymorphic type arguments of \verb|f|.

Despite the importance of type inference in practice and also in
academic research, there is little work in mechanically formalizing
such advanced forms of type inference in theorem provers.
The remarkable exception is some work done on the formalization of 
certain parts of Hindley-Milner type inference~\cite{}\bruno{all previous work on mechanizing HM}. However
there is still no formalization of the higher-ranked type systems
that are employeed by modern languages like Haskell.
This is at
odds with the current trend of mechanical formalizations in
programming language research. In particular both the POPLMark
challenge~\cite{} and CompCert ~\cite{} have significantly promoted
the use of theorem provers to model various aspects of programming
languages. Today there are routinely papers in top conferences
that use theorem provers to mechanically formalize: \emph{dynamic and
  static semantics} and their correctness properties~\cite{},
\emph{compiler correctness}~\cite{}, \emph{correctness of
  optimizations}~\cite{}, certain forms of \emph{abstract
  interpretation}\bruno{van Horn and colleagues} or proofs involving \emph{logical relations}\bruno{See Andreas Abel new paper}. The
main argument for mechanical formalizations is a simple one. Proofs
for programming languages tend to be \emph{long}, \emph{tedious} and
\emph{error-prone}. In such proofs it is very easy to make mistakes
that may invalidate the whole development. Furthermore, readers and
reviewers often do not have time to look at the proofs carefuly to
check their correctnessness. Therefore errors can go unnoticed for a
long time.  Mechanical formalizations provide, in principle, a natural
solution for such problems. Theorem provers can automaticaly check and
validate the proofs, which removes the burden from checking from both
the person doing the proofs as well as readers or reviewers.

This paper presents the first full mechanical formalization of the
metatheory for higher-ranked polymorphic type inference.
The system
that we formalize is the bidirectional type system by Dunfield and
Krishnaswami (DK)~\cite{}. We chose DK's type system because it is
quite elegant, well-documented and it comes with detailed manually
written proofs. Furthermore the system is adopted in practice by a few
real implementations of functional languages, including PureScript and
\bruno{others}.  The DK type system has two variants: a declarative
and an algorithmic one. The two variants have been been
\emph{manually} proved to be \emph{sound}, \emph{complete} and
\emph{decidable}.
We present a mechanical formalization in the Abella theorem prover for
DK's declarative type system using a different algorithm. While our
initial goal was to formalize both DK's declarative and algorithmic
versions, we faced technical challenges with the later, prompting us to find
an alternative.

One key challenge in type inference is variable binding, because the
algorithms typically do not rely simply on local environments, but
instead propagate information across judgements.  Yet, there is little
work on how to deal with these complex forms of binding in theorem
provers. To keep track of variable scoping, DK's algorithmic version
employs input and output contexts to track information that is
discovered throught type inference. However modelling output contexts
in a theorem prover is non-trivial. Our work takes a different
approach by refining and extending the idea of \emph{worklists
  judgments}~\cite{}, proposed recently to mechanically formalize an
algorithm for \emph{polymorphic subtyping}.  However, a key challenge
not addressed previously with worklist judgements was how to deal with
\emph{inference judgements}.  In our work we show how worklist
judgements can be extended to deal with the inference judgements that
are necessary for type-inference.  The idea is to use a continuation
passing style to enable the transfer of inferred information across
judgements. A further refinement to the idea of worklist judgements is
the \emph{unification between ordered contexts~\cite{}\bruno{DK and the work by McBride (see ITP citations)} and
  worklists}. This enables precise scope tracking of free variables in
judgements. Furthermore it avoids the duplication of context
information across judgments in worklists that occurs in other
techniques~\cite{}\bruno{cite the two works we cited in ITP (and maybe others)}.

Finally, another challenge that we faced were missing details and
sometimes incorrect proofs/lemmas in DK's formalization. While DK's
original formalization comes with very well written manual proofs,
there are still several details missing. These complicate the task of
writing a mechanically verified proof. Moreover some proofs and/or
lemmas are wrong and sometimes it is not clear how to replace these by
other valid lemmas or proofs. Although there are problems in DK's manual formalization
we believe that their results are true and these problems do not
invalidate their work. In fact we have nothing but praise to their detailed
and clearly written metatheory and proofs, which provided invaluable
help to our own work.
With some additional thought we expect that the issues
are fixable. We believe that for most non-trivial manual
proofs similar problems exist, so this should not be understood as a sign of sloppiness
on their part. Instead it should be an indicator that reinforces the arguments
for mechanical formalizations: manual formalizations are error-prone due to the multiple
tedious details involved in them.
There are several other examples of manual formalizations that were found to have
similar problems. For example, Klein et al.~\cite{}\bruno{Run your research} mechanized formalizations
in Redex for nine ICFP 2009 papers and all were found to have mistakes.

Despite the use of a different algorithm we prove the
same results by DK, although with significantly different proofs and
proof techniques. The calculus and its metatheory
have been fully formalized in the Abella theorem prover~\cite{AbellaDesc}.

In summary, the contributions of this paper are:

\begin{itemize}

\item {\bf A full mechanical formalization of type inference with
  higher-ranked types:} Our work presents the first full mechanical formalization
  for type inference of higher ranked types. The formalization is done in the
  Abella theorem prover~\cite{AbellaDesc} and it is available
  online.\footnote{{\bf Note to reviewers:} Due to the anonymous submission process
  the url is sent as part of the supplementary materials.}

\item {\bf A new algorithm for DK's type system:} Our work proposes a novel algorithm that implements
  DK's declarative bidirectional type system. We prove
  \emph{soundness}, \emph{completeness} and
  \emph{decidability}. 

\item {\bf Worklists with inference judgments:} One technical contribution is the
  support for inference judgments using worklists. The idea is to
  use a continuation passing style to enable the transfer of inferred information across
  judgements. 

\item {\bf Unified judgment worklists and contexts:} Another technical contribution is the unification
  between ordered contexts and judgement worklists. This enables precise scope tracking
  of variables in judgements, and avoids the duplication of context information across
  judgments in worklists.

\jimmy{Notes @20190211 4 points of novalty:\\
1) Dealing with inference judgements and CPS-style chains\\
2) The form of the judgment itself with a single shared context\\
3) The way we deal with scope (which may follow from 2)\\
4) Immediate substitution (judgment list)
}

\end{itemize}
