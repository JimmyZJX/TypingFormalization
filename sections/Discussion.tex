\section{Discussion}

% \subsection{Overlapping Rules} Already discussed in previous sections

This section discusses some insights that we gained from our work and contrast
the scoping mechanisms employed by us with those DK's original algorithm.
We also discuss a way to improve their scoping tracking precision.
Furthermore we discuss and sketch out an extension of the our algorithm with
elaboration to a target calculus.

\begin{comment}
\subsection{Implementation}
Anything to say about the implementation? Do we have one?
\end{comment}

\subsection{Contrasting our scoping mechanisms with DK's scoping}\label{sec:discussion:scoping}

One nice feature of our worklists is that scoping of variables can be
made precise, simply by interleaving variable declarations and
judgement chains.  DK's algorithm deals with garbage variables in a
different way through type variables or existential variable
markers (as discussed in Section~\ref{ssec:DK_Algorithm}).  Despite
the sophistication employed in DK's algorithm to keep scoping precise,
there is still a chance that unused existential variables leak their
scope to an output context and accumulate indefinitely.
For example, the derivation of the judgment $(\lam x)~() \Lto 1$ is as follows
$$
\inferrule*
{
    \inferrule*
    {
        \inferrule*
        {
            \inferrule*
            {\ldots x \To \al \ldots \\ \ldots \al \le \bt \ldots}
            {\Gm, \al, \bt, x:\al \vdash x \Lto \bt \dashv \Gm_1, x:\al}
        }
        {\Gm \vdash \lam x \To \al \to \bt \dashv \Gm_1}
        \\
        \inferrule*
        {\ldots () \Lto \al \ldots}
        {\Gm_1 \vdash \appInf{\al \to \al}{()}{\al} \dashv \Gm_2}
    }
    {\Gm \vdash (\lam x)~() \To \al \dashv \Gm_2}
    \\
    \inferrule*
    {~}
    {\Gm_2 \vdash 1 \le 1 \dashv \Gm_2}
}
{\Gm \vdash (\lam x)~() \Lto 1 \dashv \Gm, \al = 1, \bt = \al}
$$
where $\Gm_1 := (\Gm, \al, \bt = \al$) solves $\bt$,
and $\Gm_2 := (\Gm, \al = 1, \bt = \al$) solves both $\al$ and $\bt$.

If the reader is not familiar with DK's algorithm,
he/she might be confused about the inconsistent types across judgment.
As an example, $(\lam x)~()$ synthesizes $\al$,
but the second premise of the subsumption rule uses $1$ for the result.
This is because a context application $[\Gm,\al=1,\bt=\al]\al = 1$ happens between the premises.

The existential variables $\al$ and $\bt$ are clearly not used after the subsumption rule,
but according to the algorithm, they are kept in the context
until some parent judgment recycles a block of variables,
or to the very end of a type inference task.
In that sense, DK's algorithm does not control the scoping of variables precisely enough.
%However, it is a minor issue that does not affect the soundness and completeness properties.

One may blame the inference rule for lambda functions for not collecting garbage correctly.
Here we also show another rule for application inference with a similar problem:
$$
\inferrule*[right=$\mathtt{DK\_{\to}I{\To}}$]
{\Gamma, \al, \bt, x:\al \vdash e \Lto \bt \dashv \Delta, x:\al, \Theta}
{\Gamma \vdash \lam e \To \al \to \bt \dashv \Delta}
\qquad
\inferrule*[right=$\mathtt{DK\_\forall App}$]
{\Gamma, \al \vdash [\al/a] \appInf{A}{e}{C} \dashv \Delta}
{\Gamma \vdash \appInf{\all A}{e}{C} \dashv \Delta}
$$
In contrast our algorithm collects the existential variables right after the next judgment chain:
\[\Gm \Vdash \lambda x. e \To_a \jg \rrule{25}
\Gm,\al,\bt \Vdash [\al\to\bt/a]\jg, x:\al \Vdash e\Lto \bt\]
\[\Gm \Vdash \appInfAlg{\forall a. A}{e} \rrule{27} \Gm,\al \Vdash \appInfAlg{[\al/a]A}{e}\]
But it seems impossible to achieve a similar outcome by only modifying the two rules in DK's system.
Taking $\mathtt{DK\_{\to}I{\To}}$ as an example,
the declaration or solution for $\al$ and $\bt$ may be referred to by following judgments.
Therefore leaving $\al$ and $\bt$ in the output context is the only choice,
when the next judgments are still inaccessible.

To fix the problem, one possible modification is on the algorithmic subsumption rule,
as garbage collection for a checking judgment is always safe:
$$
\inferrule*[right=$\mathtt{DK\_Sub}$]
{\Gamma, \blacktriangleright_{\al} \vdash e \To A \dashv \Theta \\
\Theta \vdash [\Theta]A \le [\Theta]B \dashv \Delta, \blacktriangleright_{\al}, \Delta'}
{\Gamma \vdash e \Lto B \dashv \Delta}
$$
Here we employ the markers in a way different from what they were originally intended for.
We create a dummy fresh $\al$ and push a marker into the inference judgement.
When the subtyping judgement is used we look for the marker and drop everything afterwards.
We pick this rule because this is the only one where a checking judgment calls an inference judgment.
And that's the point where our algorithm recycles variables---right after a judgment chain is satisfied.
After applying this patch, to our best knowledge,
DK's algorithm behaves equivalently to our algorithm in terms of variable scoping.
However this is exploiting markers in a way that they were not intended for and seems ad-hoc.

% \subsection{Scoped type variables} Not discussed for this paper

%-------------------------------------------------------------------------------
\subsection{Elaboration}
A common extension to type-inference algorithms is to have an
associated elaboration.  For example, for languages with implicit
polymorphism, it is common to have an elaboration to a variant of
System F~\cite{reynolds1983types}, which recovers type information and explicit type
applications. Therefore a natural question is whether our algorithm
can also accomodate an elaboration step.
While our algorithmic reduction does not elaborate to System F,
we believe that it is not difficult to extend the algorithm with a (type-directed) elaboration.
We explain the rought idea as follows.

Since the judgment form of our algorithmic worklist contains a collection of judgments,
elaboration expressions are also generated as a list of equal length to
the number of judgments (\emph{not judgment chains}) in the worklist.
Within expectation, subtyping judgments translate to coercions (denoted by $f$),
all three other types of judgments translate to terms in System F (denoted by $t$).
\bruno{Why distinguish coercions and terms? Coercions are just terms, right?}

Let $\Phi$ be the elaboration list, containing translated type coercions and terms:
$$\Phi ::= \nil \mid \Phi, f \mid \Phi, t$$

Then the form of our algorithmic judgment becomes:
$$\Gamma \hookrightarrow \Phi$$

We take Rule 18 as an example, rewritting small-step reduction in a relational style,
$$
\inferrule*[right=$\mathtt{Translation\_18}$]
{\Gamma \Vdash e \To_a a \le B \hookrightarrow \Phi, f, t}
{\Gamma \Vdash e \Lto B \hookrightarrow \Phi, f t}
$$
As is shown in the conclusion of the rule,
a checking judgment on the top of the worklist corresponds to a top element for elaboration.
The premise indicates that one judgment chain may relate to more than one elaboration elements,
and that the outer judgment, being processed before inner ones,
elaborates to the top element in the elaboration list.

Existential variables need special treatment, since they may be solved at any step,
or being recycled if not solved in its scope.
If an existential variable is solved, we not only propagate the solution to the rest judgments,
but also replace ocurrences in the elaboration list.
If an existential variable is recycled, meaning that it is not constrained,
we can pick any well-formed monotype as its solution.
The unit type $1$, as the simplest type in the system, is a good choice.
