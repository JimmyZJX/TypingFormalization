\section{Overview}

\bruno{I think some text/ideas-for-text can be borrowed from ITP.}

\subsection{DK's Declarative System}
Subtyping and Typing. \jimmy{Can you prepare the figures. Subtyping is already in ITP.}

\begin{figure}[t]
\[
\begin{array}{l@{\qquad}lcl}
\text{Type variables}\qquad&a, b\\[3mm]
\text{Types}\qquad&A, B, C &::=&\quad 1 \mid a \mid \forall a. A \mid A\to B\\
\text{Monotypes}\qquad&\tau &::=&\quad 1 \mid a \mid \tau_1\to \tau_2\\
\text{Contexts}\qquad&\Psi &::=&\quad \cdot \mid \Psi, a\\
%\text{Judgments}\qquad&\exps &::=&\quad \cdot \mid A \le B : \exps
\end{array}
\]
\caption{Syntax of Declarative System}\label{fig:decl:syntax}
\end{figure}

The syntax of this declarative system is shown in Figure~\ref{fig:decl:syntax}.

\begin{figure}[t]
\centering \framebox{$\Om \vdash A$}
\begin{gather*}
\inferrule*[right=$\mathtt{wf_d unit}$]
    {~}{\Om\vdash 1}
\qquad
\inferrule*[right=$\mathtt{wf_d var}$]
    {a\in\Om}{\Om\vdash a}
\qquad
\inferrule*[right=$\mathtt{wf_d{\to}}$]
    {\Om\vdash A\quad \Om\vdash B}
    {\Om\vdash A\to B}
\qquad
\inferrule*[right=$\mathtt{wf_d\forall}$]
    {\Om, a\vdash A}
    {\Om\vdash \forall a. A}
\end{gather*}

\centering \framebox{$\Om \vdash A \le B$}
\begin{gather*}
\inferrule*[right=$\mathtt{{\le}Var}$]
    {a\in\Om}{\Om\vdash a\le a}
\qquad
\inferrule*[right=$\mathtt{{\le}Unit}$]
    {~}{\Om \vdash 1 \le 1}
\qquad
\inferrule*[right=$\mathtt{{\le}{\to}}$]
    {\Om \vdash B_1 \le A_1 \quad \Om \vdash A_2 \le B_2}
    {\Om\vdash A_1\to A_2 \le B_1\to B_2}
\\
\inferrule*[right=$\mathtt{{\le}\forall L}$]
    {\Om\vdash \tau \quad \Om\vdash [\tau/a] A \le B}
    {\Om\vdash \forall a. A \le B}
\qquad
\inferrule*[right=$\mathtt{{\le}\forall R}$]
    {\Om, a\vdash A\le B}
    {\Om\vdash A \le \forall a. B}
\end{gather*}
\caption{Well-formedness of Declarative Types and Declarative Subtyping}\label{fig:decl:wf_sub}
\end{figure}

In Figure~\ref{fig:decl:wf_sub},
we give the well-formedness and subtyping relation for the declarative system.

\paragraph{Metatheory} Talk about the lemmas that are false, show counterexample. 

%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
\paragraph{Complex Scoping and Propagation}

Besides the problematic lemmas in the DK metatheory, there are other reasons to
look for an alternative algorithmic formulation of the type system that is more
amenable to mechanisation. Indeed, two aspects that are particularly
challenging to mechanise are the scoping of universal and existential type
variables, and the propagation of the instantiation of existential type
variables across judgments. 

DK is already quite disciplined on these accounts, in particular compared to
traditional constraint-based type-inference algorithms like Algorithm W which
features an implicit global scope for all type variables. Indeed, DK uses an
explicit and ordered context that tracks the relative scope of universal and
existential variables and it is careful to only instantiate existential
variables in a well-scoped manner.

Moreover, DK's algorithm carefully propagates instantiations by recording them
into the context and threading this context through all judgments.  means of
two This means that every judgments takes two contexts---an input and an output
context---rather than the conventional single context. The output context
records any new variable instantations; to propagate these instantiations to
the remaining judgements, their predecessor's output context---which is their
input context---is applied to them as a substitution.

While it works, DK's approach is still fairly involved and thus hard to reason
about in a mechanised setting. Indeed, the instantiations have to be recorded
in the context and are applied incrementally to each remaining judgment in
turn, rather than immediately to all remaining judgments at once. Also the
stack discipline of the ordered contexts does not mesh well with the use of
output contexts; explicit marker entries are needed in two places to
demarcate the end of an existential variable's scope. These are compelling 
reasons to look for a simpler algorithm that is easier to reason about in a 
mechanised setting.

%-------------------------------------------------------------------------------
\subsection{Small-Step Unification} Mention some algorithms for unification for 
dependent types that use a small-step approach. Credit them later for some ideas that 
we also employ.

Some issues to point out: Duplicated contexts (rather than shared contexts), which make 
the formalization harder since requires ``synchronizing'' things ...

%-------------------------------------------------------------------------------
\subsection{Worklist Algorithm for Subtyping}

In recent work~\cite{itp2018}, we have shown how to mechanise a variant of DK's
subtyping algorithm and shown it correct with respect to DK's declarative
subtyping judgment. This approach overcomes the problem's in DK's formulation
by using a \emph{worklist}-based judgement of the form $\Gamma \vdash \Omega$
where $\Omega$ is a worklist, i.e. a sequence, of subtyping problems of the
form $A \leq B$.  The judgement is defined by case analysis on the first
element of $\Omega$ and recursively processes the worklist until it is empty.
Using both a single common ordered context $\Gamma$ and a worklist $\Omega$ greatly
simplifies propagating the instantiation of type variables that happen in one
subtyping problem to the remaining ones.

Unfortunately, this work does not solve all problems. In particular, it has two
major limitations that prevent it from scaling to the whole DK system. 

\paragraph{Scoping Garbage} Firstly, the single common type ordered context 
$\Gamma$ does not accurately reflect the type and unification variables
currently in scope. Instead, it is an overapproximation that steadily accrues
variables, and only drops those unification variables that are instantiated.
In other words, $\Gamma$ contains ``garbage'' that is no longer in scope.
This complicates establishing the relation with the declarative system.


\paragraph{No Inference Judgments} 
Secondly and more importantly, the approach only deals with a judgement for
\emph{checking} whether one type is the subtype of another. While this may not
so be difficult to scale to the \emph{checking} mode of term typing $\Gamma
\vdash e \Leftarrow A$, it clearly lacks the functionality to support the
\emph{inference} mode of term typing $\Gamma \vdash e \Rightarrow A$. Indeed,
the latter requires not only the communication of unification variable
instantiations from one typing problem to another, but also an inferred type.

%-------------------------------------------------------------------------------
\subsection{Algorithmic Type Inference for Higher-Ranked Types: Key Ideas}

Our new algorithmic type system addresses builds on the work above, but
addresses the open problems. 

\paragraph{Scope Tracking}
Firstly, we avoid scoping garbage by blending the ordered context and the
worklist into a single syntactic sort $\Gamma$, our algorithmic worklist. This
algorithmic worklist interleaves (type and term) variables with \emph{work}
like checking or inferring types of expressions. The interleaving keeps track
of the variable scopes in the usual, natural way: each variables is in scope of
anything in front of it in the worklist. If there is nothing in front, the
variable is no longer needed and can be popped from the worklist. This way, no
garbage builds up.

\paragraph{Inference Judgements}
To express the DK inference judgements, we use a novel form of work entries in
the worklist: our algorithmic judgement chains $\omega$. In its simplest form,
such a judgement chain is just a check, like a subtyping check $A \leq B$ or a
term typecheck $e \Leftarrow A$.  The non-trivial forms of chains capture an
inference task together with the the work that depends on its outcome. For
instance, a type inference task takes the form $e \Rightarrow_a \omega$. It
denotes that we need to infer the type, say $A$, of expression $e$ and use it
in the chain $\omega$ by subsituting it for the placeholder type variable $a$.


% Our algorithm borrows some ideas from previous work, while adding new ones. 
% A small-step style processing worklists; \emph{Judgment Chains}; others. 

% Importantly we now deal with inference judgement.

